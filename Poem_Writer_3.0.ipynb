{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypiwin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import eng_to_ipa as ipa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_EPOCHS = 10\n",
    "DEFAULT_WORDS = 600\n",
    "DEFAULT_TEMP = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Poem</th>\n",
       "      <th>Form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>From fairest creatures we desire increase,\\r\\n...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>When forty winters shall besiege thy brow,\\r\\n...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Look in thy glass and tell the face thou viewe...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Unthrifty loveliness, why dost thou spend\\r\\n ...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Those hours, that with gentle work did frame\\r...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Author                                               Poem  \\\n",
       "0  William Shakespeare  From fairest creatures we desire increase,\\r\\n...   \n",
       "1  William Shakespeare  When forty winters shall besiege thy brow,\\r\\n...   \n",
       "2  William Shakespeare  Look in thy glass and tell the face thou viewe...   \n",
       "3  William Shakespeare  Unthrifty loveliness, why dost thou spend\\r\\n ...   \n",
       "4  William Shakespeare  Those hours, that with gentle work did frame\\r...   \n",
       "\n",
       "     Form  \n",
       "0  Sonnet  \n",
       "1  Sonnet  \n",
       "2  Sonnet  \n",
       "3  Sonnet  \n",
       "4  Sonnet  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Multiple_Forms.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     From fairest creatures we desire increase,\\r\\n...\n",
       "1     When forty winters shall besiege thy brow,\\r\\n...\n",
       "2     Look in thy glass and tell the face thou viewe...\n",
       "3     Unthrifty loveliness, why dost thou spend\\r\\n ...\n",
       "4     Those hours, that with gentle work did frame\\r...\n",
       "                            ...                        \n",
       "95    Whate'er the cost to me, with this farewell,\\n...\n",
       "96    If the past year were offered me again,\\nWith ...\n",
       "97    Nay, dear one, ask me not to leave thee yet.\\n...\n",
       "98    Where is the pride for which I once was blamed...\n",
       "99    I sue thee not for pity on my case.\\nIf I have...\n",
       "Name: Poem, Length: 348, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems = df['Poem'][df.Form == 'Sonnet']\n",
    "poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Number of Epochs from 1 to 20: 2\n",
      "Setting Epochs =  2\n"
     ]
    }
   ],
   "source": [
    "num = input(\"Enter Number of Epochs from 1 to 20: \")\n",
    "if num.isdigit() and int(num) <= 20 and int(num) > 0:\n",
    "    num_epochs = int(num)\n",
    "    print(\"Setting Epochs = \", num_epochs)\n",
    "    \n",
    "else:\n",
    "    num_epochs = DEFAULT_EPOCHS\n",
    "    print(\"Incorrect Input, Setting Epochs = \", num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258640"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''\n",
    "for poem in poems:\n",
    "    text += str(poem) + '\\n'\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"’\", \"'\")\n",
    "text = text.replace(\"‘\", \"'\")\n",
    "text = text.replace(\"“\", \" \")\n",
    "text = text.replace(\"'d\", \"ed\")\n",
    "text = text.replace(\"(\", \"\")\n",
    "text = text.replace(\")\", \"\")\n",
    "text = text.replace(\" '\", \" \")\n",
    "text = text.replace(\"' \", \" \")\n",
    "text = text.replace('\"', '')\n",
    "text = text.replace(\"--\", \" \")\n",
    "text = text.replace(\":-\", \" \")\n",
    "text = text.replace(\"-:\", \" \")\n",
    "text = text.replace(\".-\", \" \")\n",
    "text = text.replace(\"- \", \" \")\n",
    "text = text.replace(\" -\", \" \")\n",
    "text = text.replace(\" –\", \" \")\n",
    "while text.find(\" . \") != -1:\n",
    "    text = text.replace(\" . \", \" \")\n",
    "while text.find(\"..\") != -1:\n",
    "    text = text.replace(\"..\", \".\")\n",
    "text = text.replace(\"?.\", \"? \")\n",
    "text = text.replace(\"!.\", \"! \")\n",
    "text = text.replace(\"!-\", \"! \")\n",
    "text = text.replace(\"!—\", \"! \")\n",
    "text = text.replace(\".\", \" \")\n",
    "text = text.replace(\",\", \" \")\n",
    "text = text.replace(\"\\n\",\" eol\\n\")\n",
    "text = text.replace(\"\\r\",\" \")\n",
    "text = text.replace(\"bad—the\", \"bad the\")\n",
    "text = text.replace(\"occasion—that\", \"occasion that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52225"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = text.split()\n",
    "a = 0\n",
    "roman_num = ['ii','iii','iv','v','vi','vii','viii','ix','x','xi','xii','xiii','xiv','xv','xvi','xvii',\n",
    "             'xviii','xix','xx','xxi','xxii','xxiii','xxiv','xxv','xxvi','xxvii','xxviii','xxix','xxx']\n",
    "for i in range(len(word_list) - a):\n",
    "    word_list[i - a] = word_list[i - a].lower().strip(\"“”''-.?:;!,[]~`’—&\")\n",
    "    if word_list[i - a] in ['nan','','*'] or word_list[i-a][0] == '&' or word_list[i-a].isdigit() \\\n",
    "     or word_list[i-a] in roman_num:\n",
    "        word_list.pop(i - a)\n",
    "        a += 1\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 52219\n",
      "Unique words: 6646\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "maxlen = 6                                                            \n",
    "step = 1 \n",
    "\n",
    "sentences = []                                                         \n",
    "\n",
    "next_words = []                                                        \n",
    "\n",
    "for i in range(0, len(word_list) - maxlen, step):\n",
    "    sentences.append(word_list[i: i + maxlen])\n",
    "    next_words.append(word_list[i + maxlen])\n",
    "\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "words = sorted(list(set(word_list)))                                        \n",
    "print('Unique words:', len(words))\n",
    "word_indices = dict((word, words.index(word)) for word in words)       \n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(words)), dtype=np.bool)      \n",
    "y = np.zeros((len(sentences), len(words)), dtype=np.bool)              \n",
    "for i, sentence in enumerate(sentences):                               \n",
    "    for t, word in enumerate(sentence):                                \n",
    "        x[i, t, word_indices[word]] = 1                                \n",
    "    y[i, word_indices[next_words[i]]] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\kyle_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "d = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to add phonems for each word to 'phonem' dict\n",
    "def syls(word):\n",
    "    flag = False\n",
    "    r_word = word[:]\n",
    "    while len(r_word) > 0 and flag == False:\n",
    "        try:\n",
    "            phonem[word] = d[r_word.lower()]\n",
    "            flag = True        # if no exception occurs then flag is set indicating phonems added to dict\n",
    "        except Exception as e:\n",
    "            r_word = r_word[1:]\n",
    "    if r_word == '':\n",
    "        phonem[word] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initializes the phonem dict\n",
    "phonem = {}\n",
    "# calls the 'syls' method for each word in the 'words' list\n",
    "for w in words:\n",
    "    syls(w)\n",
    "# phonem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(256, input_shape=(maxlen, len(words))))\n",
    "model.add(layers.Dense(len(words), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyming_words(word):\n",
    "    if word != '':\n",
    "        for key in phonem:\n",
    "            len_key = len(phonem[key])\n",
    "            for i in range(len(phonem[word])):\n",
    "                for j in range(len_key):\n",
    "                    if word == key or len_key == 0:\n",
    "                        continue\n",
    "                    elif len(phonem[word]) == 1:\n",
    "                        if phonem[word][i][-1] == phonem[key][j][-1]:\n",
    "                            rhymers.append(key)\n",
    "                    elif len(phonem[key]) == 2:\n",
    "                        if phonem[word][i][-2:] == phonem[key][j][-2:]:\n",
    "                            rhymers.append(key)\n",
    "                    else:\n",
    "                        if phonem[word][i][-3:] == phonem[key][j][-3:]:\n",
    "                            rhymers.append(key)\n",
    "#     print(len(rhymers))\n",
    "    \n",
    "                                           \n",
    "def syllable_counter(word):\n",
    "    count = 0\n",
    "    if word == '' or word == '\\n':\n",
    "        count = 0\n",
    "    elif ipa.syllable_count(word) == 0:\n",
    "        count = len(word) % 3\n",
    "        if count == 0:\n",
    "            count = 1\n",
    "    else:\n",
    "        count += ipa.syllable_count(word)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3==2.71 in c:\\users\\kyle_\\anaconda3\\lib\\site-packages (2.71)\n",
      "Requirement already satisfied: pypiwin32; \"win32\" in sys_platform in c:\\users\\kyle_\\anaconda3\\lib\\site-packages (from pyttsx3==2.71) (223)\n",
      "Requirement already satisfied: pywin32>=223 in c:\\users\\kyle_\\anaconda3\\lib\\site-packages (from pypiwin32; \"win32\" in sys_platform->pyttsx3==2.71) (227)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3==2.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# importing the pyttsx library\n",
    "import pyttsx3\n",
    "#initialisation\n",
    "# engine = pyttsx3.init('sapi5')\n",
    "# # voices = engine.getProperty('voices')\n",
    "# # engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "\n",
    "# # def speak(audio):\n",
    "# #     engine.say(audio)\n",
    "# #     engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = pyttsx3.init()\n",
    "rate = engine.getProperty('rate')\n",
    "engine.setProperty('rate', rate - 100)\n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say('in aftertimes will say of you I be fire and the, \\\n",
    " Of the old of the fortitude the world, \\\n",
    " And thy the heart of the o I not wreathe, \\\n",
    " And not with in the world not head')\n",
    "engine.runAndWait()\n",
    "engine.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1\n",
      "Epoch 1/1\n",
      "52219/52219 [==============================] - 153s 3ms/step - loss: 6.3863\n",
      "--- Generating with seed: \"in aftertimes will say of you\"\n",
      "------ temperature: 0.5\n",
      "in aftertimes will say of you I be fire and the \n",
      " Of the old of the fortitude the world \n",
      " And thy the heart of the o I not wreathe \n",
      " And not with in the world not head"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-fea154021d11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0mnext_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[0mnext_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msyllable_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;31m#                     sys.stdout.write('     FOURTH LINE')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                     \u001b[0mline_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-ed89db517b86>\u001b[0m in \u001b[0;36msyllable_counter\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mipa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyllable_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\eng_to_ipa\\syllables.py\u001b[0m in \u001b[0;36msyllable_count\u001b[1;34m(word, db_type)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msyllable_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranscribe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdb_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcmu_syllable_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\eng_to_ipa\\transcribe.py\u001b[0m in \u001b[0;36mget_cmu\u001b[1;34m(tokens_in, db_type)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_cmu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sql\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;34m\"\"\"query the SQL database for the words and return the phonemes in the order of user_in\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[0mordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\eng_to_ipa\\transcribe.py\u001b[0m in \u001b[0;36mfetch_words\u001b[1;34m(words_in, db_type)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mquest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"?, \"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0masset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT word, phonemes FROM dictionary WHERE word IN ({0})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%b-%d-%Y_%H%M', t)\n",
    "FILE_NAME = (\"poem_output_\" + timestamp + \".txt\")\n",
    "file = open(FILE_NAME, 'a')\n",
    "\n",
    "RHYME_CHECK = 5\n",
    "\n",
    "model_loss = {}\n",
    "model_loss['loss'] = []\n",
    "\n",
    "line_count = 0\n",
    "quatrain_count = 0\n",
    "quatrain = False\n",
    "new_line = False\n",
    "app_word = ''\n",
    "end_of_line = False\n",
    "\n",
    "generated_text = ''\n",
    "count = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    generated_text = ''\n",
    "    generated_list = []\n",
    "    print('\\nepoch', epoch)\n",
    "    hist = model.fit(x, y, batch_size=128, epochs=1)\n",
    "    model_loss['loss'].append(hist.history['loss'][0])\n",
    "    start_index = random.randint(0, len(word_list) - maxlen - 1)         \n",
    "    generated_list = word_list[start_index: start_index + maxlen]\n",
    "\n",
    "    for word in generated_list:\n",
    "        generated_text += word + ' '\n",
    "    generated_text =  generated_text.strip()\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "    file.write('--- Generating with seed: \"' + generated_text + '\"\\n')\n",
    "    for num in ipa.syllable_count(generated_text):\n",
    "        count += num\n",
    "    for temperature in [0.5, 1.0, 1.2]:                        \n",
    "        print('------ temperature:', temperature)\n",
    "        file.write('------ temperature: ' + str(temperature) + '\\n')\n",
    "        sys.stdout.write(generated_text)\n",
    "        file.write(generated_text)\n",
    "\n",
    "        for i in range(400):                                        \n",
    "            sampled = np.zeros((1, maxlen, len(words)))             \n",
    "            for t, word in enumerate(generated_list):               \n",
    "                sampled[0, t, word_indices[word]] = 1. \n",
    "                \n",
    "            if count >= 10:\n",
    "                end_of_line = True\n",
    "#                 sys.stdout.write('\\n')\n",
    "#                 file.write('\\n')\n",
    "                count = 0 \n",
    "#                 new_line = True\n",
    "\n",
    "            if line_count == 2 and count >= RHYME_CHECK:\n",
    "                preds = model.predict(sampled, verbose=0)[0] * z1\n",
    "                next_index = sample(preds, temperature)                 \n",
    "                next_word = words[next_index]\n",
    "                if count + syllable_counter(next_word) >= 10:\n",
    "#                     sys.stdout.write(' THIRD LINE')\n",
    "#                     print(' WORD:', next_word, end='')\n",
    "                    line_count += 1 \n",
    "#                     print(f' LC {line_count} QC {quatrain_count} COUNT {count}', end='')\n",
    "                    if quatrain_count == 3:\n",
    "                        line_count += 1\n",
    "                        quatrain_count = 0\n",
    "                else:\n",
    "                    preds = model.predict(sampled, verbose=0)[0]\n",
    "                    next_index = sample(preds, temperature)                 \n",
    "                    next_word = words[next_index]\n",
    "                    while (count + syllable_counter(next_word)) >= 10:\n",
    "                        next_index = sample(preds, temperature)                 \n",
    "                        next_word = words[next_index] \n",
    "               \n",
    "            elif line_count == 3 and count >= RHYME_CHECK:\n",
    "                preds = model.predict(sampled, verbose=0)[0] * z2\n",
    "                next_index = sample(preds, temperature)                 \n",
    "                next_word = words[next_index]\n",
    "                if (count + syllable_counter(next_word) >= 10):\n",
    "#                     sys.stdout.write('     FOURTH LINE')\n",
    "                    line_count += 1\n",
    "                    quatrain_count += 1\n",
    "                else:\n",
    "                    preds = model.predict(sampled, verbose=0)[0]\n",
    "                    next_index = sample(preds, temperature)                 \n",
    "                    next_word = words[next_index]\n",
    "                    while (count + syllable_counter(next_word)) >= 10:\n",
    "                        next_index = sample(preds, temperature)                 \n",
    "                        next_word = words[next_index] \n",
    "\n",
    "            else:\n",
    "                preds = model.predict(sampled, verbose=0)[0]\n",
    "                next_index = sample(preds, temperature)                 \n",
    "                next_word = words[next_index]\n",
    "                \n",
    "            if count < 10 and next_word == 'eol':\n",
    "                next_word = ''\n",
    "                app_word = generated_list[maxlen - 1]\n",
    "            elif end_of_line:\n",
    "                app_word = next_word = 'eol'\n",
    "                end_of_line = False\n",
    "                count = 0\n",
    "            else:\n",
    "                app_word = next_word\n",
    "\n",
    "            generated_list.append(app_word)\n",
    "            generated_list = generated_list[1:]\n",
    "\n",
    "            if new_line and next_word == 'eol':\n",
    "                next_word = ''\n",
    "            elif new_line:\n",
    "                next_word = next_word.capitalize()\n",
    "                new_line = False\n",
    "            elif next_word == 'i':\n",
    "                next_word = next_word.upper()\n",
    "            elif next_word == 'eol':\n",
    "                next_word = '\\n'\n",
    "                new_line = True\n",
    "            if next_word != '':    \n",
    "                sys.stdout.write(' ' + next_word)\n",
    "                file.write(' ' + next_word)\n",
    "#                 engine.say(next_word)\n",
    "#                 engine.runAndWait()\n",
    "#                 engine.stop()\n",
    "                syl_num = syllable_counter(next_word)\n",
    "                count += syl_num\n",
    "\n",
    "            if count >= 10:\n",
    "                if line_count == 0:\n",
    "#                     sys.stdout.write('     FIRST LINE')\n",
    "                    rhymers = []\n",
    "                    z1 = np.zeros(len(words)) + 0.0001\n",
    "#                     print(\"\\nNext Word:\", next_word)\n",
    "                    r_word = next_word[:].lower()\n",
    "                    r_word = r_word.strip(\",.?!:;-'\\\"_\")   \n",
    "#                     print(r_word)\n",
    "                    rhyming_words(r_word)\n",
    "#                     print(rhymers)\n",
    "                    for rhyme in rhymers:\n",
    "                        if rhyme in word_indices:\n",
    "                            z1[word_indices[rhyme]] = 10000.\n",
    "                    line_count += 1\n",
    "                    if quatrain_count == 3:\n",
    "                        line_count += 1\n",
    "\n",
    "                elif line_count == 1:\n",
    "#                     sys.stdout.write('  SECOND LINE')\n",
    "                    rhymers = []\n",
    "                    z2 = np.zeros(len(words)) + 0.0001\n",
    "#                     print(\"\\nNext Word:\", next_word)\n",
    "                    r_word = next_word[:].lower()\n",
    "                    r_word = r_word.strip(\",.?!:;-'\\\"_\")   \n",
    "#                     print(r_word)\n",
    "                    rhyming_words(r_word)\n",
    "#                     print(rhymers)\n",
    "                    for rhyme in rhymers:\n",
    "                        if rhyme in word_indices:\n",
    "                            z2[word_indices[rhyme]] = 10000.\n",
    "                    line_count += 1\n",
    "#                     print('     LINE COUNT:', line_count, end = '')\n",
    "\n",
    "                elif line_count == 4:\n",
    "                    print()\n",
    "                    file.write('\\n')\n",
    "                    line_count = 0\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x for x in range(len(model_loss['loss']))], model_loss['loss'], label = 'Training Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gtts import gTTS\n",
    "# import os\n",
    "# language = 'en'\n",
    "# myobj = gTTS(text=generated_text, lang=language, slow=False)\n",
    "# myobj.save('welcome.mp3')\n",
    "# os.system('welcome.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
