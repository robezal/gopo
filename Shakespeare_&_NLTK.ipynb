{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Poem</th>\n",
       "      <th>Form</th>\n",
       "      <th>Era</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>I</td>\n",
       "      <td>From fairest creatures we desire increase,\\r\\n...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>II</td>\n",
       "      <td>When forty winters shall besiege thy brow,\\r\\n...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>III</td>\n",
       "      <td>Look in thy glass and tell the face thou viewe...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>IV</td>\n",
       "      <td>Unthrifty loveliness, why dost thou spend\\r\\n ...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>V</td>\n",
       "      <td>Those hours, that with gentle work did frame\\r...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               Author Title  \\\n",
       "0           0  William Shakespeare     I   \n",
       "1           1  William Shakespeare    II   \n",
       "2           2  William Shakespeare   III   \n",
       "3           3  William Shakespeare    IV   \n",
       "4           4  William Shakespeare     V   \n",
       "\n",
       "                                                Poem    Form          Era  \\\n",
       "0  From fairest creatures we desire increase,\\r\\n...  Sonnet  Renaissance   \n",
       "1  When forty winters shall besiege thy brow,\\r\\n...  Sonnet  Renaissance   \n",
       "2  Look in thy glass and tell the face thou viewe...  Sonnet  Renaissance   \n",
       "3  Unthrifty loveliness, why dost thou spend\\r\\n ...  Sonnet  Renaissance   \n",
       "4  Those hours, that with gentle work did frame\\r...  Sonnet  Renaissance   \n",
       "\n",
       "   Type  \n",
       "0  Love  \n",
       "1  Love  \n",
       "2  Love  \n",
       "3  Love  \n",
       "4  Love  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Shakespeare_Sonnets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for poem in df.Poem[:10]:\n",
    "    text += poem + '\\n'\n",
    "\n",
    "# print(type(text))\n",
    "train_text = text\n",
    "sample_text = df.Poem[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As fast as thou shalt wane, so fast thou grow'st,\r\n",
      "  In one of thine, from that which thou departest;\r\n",
      "  And that fresh blood which youngly thou bestow'st,\r\n",
      "  Thou mayst call thine when thou from youth convertest,\r\n",
      "  Herein lives wisdom, beauty, and increase;\r\n",
      "  Without this folly, age, and cold decay:\r\n",
      "  If all were minded so, the times should cease\r\n",
      "  And threescore year would make the world away.\n",
      "\n",
      "Let those whom nature hath not made for store,\r\n",
      "  Harsh, featureless, and rude, barrenly perish:\r\n",
      "  Look, whom she best endow'd, she gave thee more;\r\n",
      "  Which bounteous gift thou shouldst in bounty cherish:\r\n",
      "        She carv'd thee for her seal, and meant thereby,\r\n",
      "        Thou shouldst print more, not let that copy die.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len(tokenized)\n",
    "for token in tokenized:\n",
    "    print(f'{token}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('As', 'IN'), ('fast', 'RB'), ('as', 'IN'), ('thou', 'NN'), ('shalt', 'NN'), ('wane', 'NN'), (',', ','), ('so', 'IN'), ('fast', 'JJ'), ('thou', 'NN'), (\"grow'st\", 'NN'), (',', ','), ('In', 'IN'), ('one', 'CD'), ('of', 'IN'), ('thine', 'NN'), (',', ','), ('from', 'IN'), ('that', 'DT'), ('which', 'WDT'), ('thou', 'VBP'), ('departest', 'NN'), (';', ':'), ('And', 'CC'), ('that', 'IN'), ('fresh', 'JJ'), ('blood', 'NN'), ('which', 'WDT'), ('youngly', 'RB'), ('thou', 'VBZ'), (\"bestow'st\", 'NN'), (',', ','), ('Thou', 'NNP'), ('mayst', 'NN'), ('call', 'NN'), ('thine', 'NN'), ('when', 'WRB'), ('thou', 'NN'), ('from', 'IN'), ('youth', 'NN'), ('convertest', 'NN'), (',', ','), ('Herein', 'NNP'), ('lives', 'VBZ'), ('wisdom', 'NN'), (',', ','), ('beauty', 'NN'), (',', ','), ('and', 'CC'), ('increase', 'NN'), (';', ':'), ('Without', 'IN'), ('this', 'DT'), ('folly', 'RB'), (',', ','), ('age', 'NN'), (',', ','), ('and', 'CC'), ('cold', 'JJ'), ('decay', 'NN'), (':', ':'), ('If', 'IN'), ('all', 'DT'), ('were', 'VBD'), ('minded', 'VBN'), ('so', 'RB'), (',', ','), ('the', 'DT'), ('times', 'NNS'), ('should', 'MD'), ('cease', 'VB'), ('And', 'CC'), ('threescore', 'IN'), ('year', 'NN'), ('would', 'MD'), ('make', 'VB'), ('the', 'DT'), ('world', 'NN'), ('away', 'RB'), ('.', '.')]\n",
      "[('Let', 'VB'), ('those', 'DT'), ('whom', 'WP'), ('nature', 'VBP'), ('hath', 'NN'), ('not', 'RB'), ('made', 'VBN'), ('for', 'IN'), ('store', 'NN'), (',', ','), ('Harsh', 'NNP'), (',', ','), ('featureless', 'NN'), (',', ','), ('and', 'CC'), ('rude', 'NN'), (',', ','), ('barrenly', 'RB'), ('perish', 'JJ'), (':', ':'), ('Look', 'NN'), (',', ','), ('whom', 'WP'), ('she', 'PRP'), ('best', 'JJS'), ('endow', 'NN'), (\"'d\", 'NN'), (',', ','), ('she', 'PRP'), ('gave', 'VBD'), ('thee', 'RB'), ('more', 'RBR'), (';', ':'), ('Which', 'NNP'), ('bounteous', 'VBZ'), ('gift', 'NN'), ('thou', 'NN'), ('shouldst', 'NN'), ('in', 'IN'), ('bounty', 'JJ'), ('cherish', 'NN'), (':', ':'), ('She', 'PRP'), ('carv', 'VBZ'), (\"'d\", 'MD'), ('thee', 'VB'), ('for', 'IN'), ('her', 'PRP$'), ('seal', 'NN'), (',', ','), ('and', 'CC'), ('meant', 'JJ'), ('thereby', 'NN'), (',', ','), ('Thou', 'NNP'), ('shouldst', 'VBD'), ('print', 'NN'), ('more', 'RBR'), (',', ','), ('not', 'RB'), ('let', 'VB'), ('that', 'IN'), ('copy', 'NN'), ('die', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for token in tokenized:\n",
    "            words = nltk.word_tokenize(token)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tag list:\n",
    "\n",
    "# CC\tcoordinating conjunction\n",
    "# CD\tcardinal digit\n",
    "# DT\tdeterminer\n",
    "# EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "# FW\tforeign word\n",
    "# IN\tpreposition/subordinating conjunction\n",
    "# JJ\tadjective\t'big'\n",
    "# JJR\tadjective, comparative\t'bigger'\n",
    "# JJS\tadjective, superlative\t'biggest'\n",
    "# LS\tlist marker\t1)\n",
    "# MD\tmodal\tcould, will\n",
    "# NN\tnoun, singular 'desk'\n",
    "# NNS\tnoun plural\t'desks'\n",
    "# NNP\tproper noun, singular\t'Harrison'\n",
    "# NNPS\tproper noun, plural\t'Americans'\n",
    "# PDT\tpredeterminer\t'all the kids'\n",
    "# POS\tpossessive ending\tparent\\'s\n",
    "# PRP\tpersonal pronoun\tI, he, she\n",
    "# PRP$\tpossessive pronoun\tmy, his, hers\n",
    "# RB\tadverb\tvery, silently,\n",
    "# RBR\tadverb, comparative\tbetter\n",
    "# RBS\tadverb, superlative\tbest\n",
    "# RP\tparticle\tgive up\n",
    "# TO\tto\tgo 'to' the store.\n",
    "# UH\tinterjection\terrrrrrrrm\n",
    "# VB\tverb, base form\ttake\n",
    "# VBD\tverb, past tense\ttook\n",
    "# VBG\tverb, gerund/present participle\ttaking\n",
    "# VBN\tverb, past participle\ttaken\n",
    "# VBP\tverb, sing. present, non-3d\ttake\n",
    "# VBZ\tverb, 3rd person sing. present\ttakes\n",
    "# WDT\twh-determiner\twhich\n",
    "# WP\twh-pronoun\twho, what\n",
    "# WP$\tpossessive wh-pronoun\twhose\n",
    "# WRB\twh-abverb\twhere, when"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
