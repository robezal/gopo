{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOPO Poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import eng_to_ipa as ipa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default values for epochs, number of words to output, and the randomization factor\n",
    "DEFAULT_EPOCHS = 10\n",
    "DEFAULT_WORDS = 600\n",
    "DEFAULT_TEMP = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read poetry into a dataframe and extract the poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Poem</th>\n",
       "      <th>Form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>From fairest creatures we desire increase,\\r\\n...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>When forty winters shall besiege thy brow,\\r\\n...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Look in thy glass and tell the face thou viewe...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Unthrifty loveliness, why dost thou spend\\r\\n ...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Those hours, that with gentle work did frame\\r...</td>\n",
       "      <td>Sonnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Author                                               Poem  \\\n",
       "0  William Shakespeare  From fairest creatures we desire increase,\\r\\n...   \n",
       "1  William Shakespeare  When forty winters shall besiege thy brow,\\r\\n...   \n",
       "2  William Shakespeare  Look in thy glass and tell the face thou viewe...   \n",
       "3  William Shakespeare  Unthrifty loveliness, why dost thou spend\\r\\n ...   \n",
       "4  William Shakespeare  Those hours, that with gentle work did frame\\r...   \n",
       "\n",
       "     Form  \n",
       "0  Sonnet  \n",
       "1  Sonnet  \n",
       "2  Sonnet  \n",
       "3  Sonnet  \n",
       "4  Sonnet  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Multiple_Forms.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     From fairest creatures we desire increase,\\r\\n...\n",
       "1     When forty winters shall besiege thy brow,\\r\\n...\n",
       "2     Look in thy glass and tell the face thou viewe...\n",
       "3     Unthrifty loveliness, why dost thou spend\\r\\n ...\n",
       "4     Those hours, that with gentle work did frame\\r...\n",
       "                            ...                        \n",
       "95    Whate'er the cost to me, with this farewell,\\n...\n",
       "96    If the past year were offered me again,\\nWith ...\n",
       "97    Nay, dear one, ask me not to leave thee yet.\\n...\n",
       "98    Where is the pride for which I once was blamed...\n",
       "99    I sue thee not for pity on my case.\\nIf I have...\n",
       "Name: Poem, Length: 348, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems = df['Poem'][df.Form == 'Sonnet']\n",
    "poems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258640"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''\n",
    "for poem in poems:\n",
    "    text += str(poem) + '\\n'\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"’\", \"'\")\n",
    "text = text.replace(\"‘\", \"'\")\n",
    "text = text.replace(\"“\", \" \")\n",
    "text = text.replace(\"'d\", \"ed\")\n",
    "text = text.replace(\"(\", \"\")\n",
    "text = text.replace(\")\", \"\")\n",
    "text = text.replace(\" '\", \" \")\n",
    "text = text.replace(\"' \", \" \")\n",
    "text = text.replace('\"', '')\n",
    "text = text.replace(\"--\", \" \")\n",
    "text = text.replace(\":-\", \" \")\n",
    "text = text.replace(\"-:\", \" \")\n",
    "text = text.replace(\".-\", \" \")\n",
    "text = text.replace(\"- \", \" \")\n",
    "text = text.replace(\" -\", \" \")\n",
    "text = text.replace(\" –\", \" \")\n",
    "while text.find(\" . \") != -1:\n",
    "    text = text.replace(\" . \", \" \")\n",
    "while text.find(\"..\") != -1:\n",
    "    text = text.replace(\"..\", \".\")\n",
    "text = text.replace(\"?.\", \"? \")\n",
    "text = text.replace(\"!.\", \"! \")\n",
    "text = text.replace(\"!-\", \"! \")\n",
    "text = text.replace(\"!—\", \"! \")\n",
    "text = text.replace(\".\", \" \")\n",
    "text = text.replace(\",\", \" \")\n",
    "text = text.replace(\"\\n\",\" eol\\n\")\n",
    "text = text.replace(\"\\r\",\" \")\n",
    "text = text.replace(\"bad—the\", \"bad the\")\n",
    "text = text.replace(\"occasion—that\", \"occasion that\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Convert text string into a list and clean it some more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52224"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = text.split()\n",
    "a = 0\n",
    "roman_num = ['ii','iii','iv','v','vi','vii','viii','ix','x','xi','xii','xiii','xiv','xv','xvi','xvii',\n",
    "             'xviii','xix','xx','xxi','xxii','xxiii','xxiv','xxv','xxvi','xxvii','xxviii','xxix','xxx']\n",
    "for i in range(len(word_list) - a):\n",
    "    word_list[i - a] = word_list[i - a].lower().strip(\"“”''-.?:;!,[]~`’—&\")\n",
    "    if word_list[i - a] in ['nan','','*','st'] or word_list[i-a][0] == '&' or word_list[i-a].isdigit() \\\n",
    "     or word_list[i-a] in roman_num:\n",
    "        word_list.pop(i - a)\n",
    "        a += 1\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sorted list of the unique words, vectorize the words and sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 52218\n",
      "Unique words: 6645\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "maxlen = 6                                                            \n",
    "step = 1 \n",
    "\n",
    "sentences = []                                                         \n",
    "\n",
    "next_words = []                                                        \n",
    "\n",
    "for i in range(0, len(word_list) - maxlen, step):\n",
    "    sentences.append(word_list[i: i + maxlen])\n",
    "    next_words.append(word_list[i + maxlen])\n",
    "\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "words = sorted(list(set(word_list)))                                        \n",
    "print('Unique words:', len(words))\n",
    "word_indices = dict((word, words.index(word)) for word in words)       \n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(words)), dtype=np.bool)      \n",
    "y = np.zeros((len(sentences), len(words)), dtype=np.bool)              \n",
    "for i, sentence in enumerate(sentences):                               \n",
    "    for t, word in enumerate(sentence):                                \n",
    "        x[i, t, word_indices[word]] = 1                                \n",
    "    y[i, word_indices[next_words[i]]] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import phonem library and create a dictionary of words and their phonems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\kyle_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "d = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to add phonems for each word to 'phonem' dict\n",
    "def syls(word):\n",
    "    flag = False\n",
    "    r_word = word[:]\n",
    "    while len(r_word) > 0 and flag == False:\n",
    "        try:\n",
    "            phonem[word] = d[r_word.lower()]\n",
    "            flag = True        # if no exception occurs then flag is set indicating phonems added to dict\n",
    "        except Exception as e:\n",
    "            r_word = r_word[1:]\n",
    "    if r_word == '':\n",
    "        phonem[word] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initializes the phonem dict\n",
    "phonem = {}\n",
    "# calls the 'syls' method for each word in the 'words' list\n",
    "for w in words:\n",
    "    syls(w)\n",
    "# phonem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(512, input_shape=(maxlen, len(words))))\n",
    "model.add(layers.Dense(len(words), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to return a word probability vector\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for finding rhyming words and counting syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyming_words(word):\n",
    "    if word != '':\n",
    "        for key in phonem:\n",
    "            len_key = len(phonem[key])\n",
    "            for i in range(len(phonem[word])):\n",
    "                for j in range(len_key):\n",
    "                    if word == key or len_key == 0:\n",
    "                        continue\n",
    "                    elif len(phonem[word]) == 1:\n",
    "                        if phonem[word][i][-1] == phonem[key][j][-1]:\n",
    "                            rhymers.append(key)\n",
    "                    elif len(phonem[key]) == 2:\n",
    "                        if phonem[word][i][-2:] == phonem[key][j][-2:]:\n",
    "                            rhymers.append(key)\n",
    "                    else:\n",
    "                        if phonem[word][i][-3:] == phonem[key][j][-3:]:\n",
    "                            rhymers.append(key)\n",
    "#     print(len(rhymers))\n",
    "    \n",
    "                                           \n",
    "def syllable_counter(word):\n",
    "    count = 0\n",
    "    if word == '' or word == '\\n':\n",
    "        count = 0\n",
    "    elif ipa.syllable_count(word) == 0:\n",
    "        count = len(word) % 3\n",
    "        if count == 0:\n",
    "            count = 1\n",
    "    else:\n",
    "        count += ipa.syllable_count(word)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Reading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyttsx3==2.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# importing the pyttsx library\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the engine and set the reading rate\n",
    "engine = pyttsx3.init()\n",
    "# rate = engine.getProperty('rate')\n",
    "engine.setProperty('rate', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set values for the number of epochs, words to output, and the randomizing factor (temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Number of Epochs from 1 to 20: 11\n",
      "Setting Epochs =  11\n"
     ]
    }
   ],
   "source": [
    "# Set the number of training epochs\n",
    "num = input(\"Enter Number of Epochs from 1 to 20: \")\n",
    "if num.isdigit() and int(num) <= 20 and int(num) > 0:\n",
    "    num_epochs = int(num)\n",
    "    print(\"Setting Epochs = \", num_epochs)\n",
    "    \n",
    "else:\n",
    "    num_epochs = DEFAULT_EPOCHS\n",
    "    print(\"Incorrect Input, Setting Epochs = \", num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Number of Words to output from 100 to 1600: 100\n",
      "Setting # of words =  100\n"
     ]
    }
   ],
   "source": [
    "# Set the number of words to output\n",
    "num = input(\"Enter Number of Words to output from 100 to 1600: \")\n",
    "if num.isdigit() and int(num) <= 1600 and int(num) >= 100:\n",
    "    num_words = int(num)\n",
    "    print(\"Setting # of words = \", num_words)\n",
    "    \n",
    "else:\n",
    "    num_words = DEFAULT_WORDS\n",
    "    print(\"Incorrect Input, Setting Words = \", num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter randomizer factor from 0.2 to 1.5: 0.9\n",
      "Setting Randomizer Factor =  0.9\n"
     ]
    }
   ],
   "source": [
    "# Set the randomization factor (temperature)\n",
    "flt = input(\"Enter randomizer factor from 0.2 to 1.5: \")\n",
    "try:\n",
    "        temperature = float(flt)\n",
    "        if temperature >= 0.2 and temperature <= 1.5:\n",
    "            print(\"Setting Randomizer Factor = \", temperature)\n",
    "        else:\n",
    "            temperature = DEFAULT_TEMP\n",
    "            print(\"Incorrect Input, Setting Randomizer Factor = \", temperature)\n",
    "except ValueError:\n",
    "        temperature = DEFAULT_TEMP\n",
    "        print(\"Incorrect Input, Setting Randomizer Factor = \", temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "52218/52218 [==============================] - 137s 3ms/step - loss: 6.8683\n",
      "Epoch 2/11\n",
      "52218/52218 [==============================] - 160s 3ms/step - loss: 6.0223\n",
      "Epoch 3/11\n",
      "52218/52218 [==============================] - 175s 3ms/step - loss: 5.4402\n",
      "Epoch 4/11\n",
      "52218/52218 [==============================] - 185s 4ms/step - loss: 4.6979\n",
      "Epoch 5/11\n",
      "52218/52218 [==============================] - 177s 3ms/step - loss: 3.6917\n",
      "Epoch 6/11\n",
      "52218/52218 [==============================] - 179s 3ms/step - loss: 2.6186\n",
      "Epoch 7/11\n",
      "52218/52218 [==============================] - 182s 3ms/step - loss: 1.6572\n",
      "Epoch 8/11\n",
      "52218/52218 [==============================] - 181s 3ms/step - loss: 0.9650\n",
      "Epoch 9/11\n",
      "52218/52218 [==============================] - 190s 4ms/step - loss: 0.5681\n",
      "Epoch 10/11\n",
      "52218/52218 [==============================] - 181s 3ms/step - loss: 0.3681\n",
      "Epoch 11/11\n",
      "25088/52218 [=============>................] - ETA: 1:27 - loss: 0.1593"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, y, batch_size=512, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input(\"Press 'Enter' to continue: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the Poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# create file with unique timestamp\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%b-%d-%Y_%H%M', t)\n",
    "FILE_NAME = (\"poem_output_\" + timestamp + \".txt\")\n",
    "file = open(FILE_NAME, 'a')\n",
    "\n",
    "# initialize variables and assign values \n",
    "RHYME_CHECK = 5\n",
    "\n",
    "model_loss = {}\n",
    "model_loss['loss'] = []\n",
    "\n",
    "line_count = 0\n",
    "quatrain_count = 0\n",
    "quatrain = False\n",
    "new_line = False\n",
    "app_word = ''\n",
    "end_of_line = False\n",
    "\n",
    "count = 0    # counts number of syllables on a line\n",
    "\n",
    "generated_text = ''\n",
    "generated_list = []\n",
    "\n",
    "# select list of words starting a randomly selected index\n",
    "start_index = random.randint(0, len(word_list) - maxlen - 1)         \n",
    "generated_list = word_list[start_index: start_index + maxlen]\n",
    "\n",
    "# create a string from the list\n",
    "for word in generated_list:\n",
    "    generated_text += word + ' '\n",
    "generated_text =  generated_text.strip()\n",
    "\n",
    "print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "file.write('--- Generating with seed: \"' + generated_text + '\"\\n')\n",
    "\n",
    "for num in ipa.syllable_count(generated_text):\n",
    "    count += num\n",
    "    \n",
    "generated_text = generated_text.replace('eol ','')\n",
    "generated_text = generated_text.capitalize()\n",
    "\n",
    "print('------ temperature:', temperature)\n",
    "file.write('------ temperature: ' + str(temperature) + '\\n')\n",
    "sys.stdout.write(' ' + generated_text)\n",
    "file.write(' ' + generated_text)\n",
    "\n",
    "# write out the words of the poems\n",
    "for i in range(num_words):                                        \n",
    "    sampled = np.zeros((1, maxlen, len(words)))             \n",
    "    for t, word in enumerate(generated_list):               \n",
    "        sampled[0, t, word_indices[word]] = 1. \n",
    "\n",
    "    if count >= 10:\n",
    "        end_of_line = True\n",
    "        count = 0 \n",
    "\n",
    "    # finds rhyming word for the end of the third line\n",
    "    if line_count == 2 and count >= RHYME_CHECK:\n",
    "        preds = model.predict(sampled, verbose=0)[0] * z1\n",
    "        next_index = sample(preds, temperature)                 \n",
    "        next_word = words[next_index]\n",
    "        if count + syllable_counter(next_word) >= 10:\n",
    "#                     sys.stdout.write(' THIRD LINE')\n",
    "#                     print(' WORD:', next_word, end='')\n",
    "            line_count += 1 \n",
    "            if quatrain_count == 3:\n",
    "                line_count += 1\n",
    "                quatrain_count = 0\n",
    "        else:\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)                 \n",
    "            next_word = words[next_index]\n",
    "            while (count + syllable_counter(next_word)) >= 10:\n",
    "                next_index = sample(preds, temperature)                 \n",
    "                next_word = words[next_index] \n",
    "\n",
    "    # finds rhyming word for the end of the fourth line\n",
    "    elif line_count == 3 and count >= RHYME_CHECK:\n",
    "        preds = model.predict(sampled, verbose=0)[0] * z2\n",
    "        next_index = sample(preds, temperature)                 \n",
    "        next_word = words[next_index]\n",
    "        if (count + syllable_counter(next_word) >= 10):\n",
    "#                     sys.stdout.write('     FOURTH LINE')\n",
    "            line_count += 1\n",
    "            quatrain_count += 1\n",
    "        else:\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)                 \n",
    "            next_word = words[next_index]\n",
    "            while (count + syllable_counter(next_word)) >= 10:\n",
    "                next_index = sample(preds, temperature)                 \n",
    "                next_word = words[next_index] \n",
    "\n",
    "    else:\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)                 \n",
    "        next_word = words[next_index]\n",
    "\n",
    "    if count < 10 and next_word == 'eol':\n",
    "        next_word = ''\n",
    "        app_word = generated_list[maxlen - 1]\n",
    "    elif end_of_line:\n",
    "        app_word = next_word = 'eol'\n",
    "        end_of_line = False\n",
    "        count = 0\n",
    "    else:\n",
    "        app_word = next_word\n",
    "\n",
    "    generated_list.append(app_word)\n",
    "    generated_list = generated_list[1:]\n",
    "\n",
    "    if new_line and next_word == 'eol':\n",
    "        next_word = ''\n",
    "    elif new_line:\n",
    "        next_word = next_word.capitalize()\n",
    "        new_line = False\n",
    "    elif next_word == 'i':\n",
    "        next_word = next_word.upper()\n",
    "    elif next_word == 'eol':\n",
    "        next_word = '\\n'\n",
    "        new_line = True\n",
    "    if next_word != '':    \n",
    "        sys.stdout.write(' ' + next_word)\n",
    "        file.write(' ' + next_word)\n",
    "        syl_num = syllable_counter(next_word)\n",
    "        count += syl_num\n",
    "\n",
    "    if count >= 10:\n",
    "        if line_count == 0:\n",
    "#                     sys.stdout.write('     FIRST LINE')\n",
    "            rhymers = []\n",
    "            z1 = np.zeros(len(words)) + 0.0001\n",
    "#                     print(\"\\nNext Word:\", next_word)\n",
    "            r_word = next_word[:].lower()\n",
    "            r_word = r_word.strip(\",.?!:;-'\\\"_\")   \n",
    "#                     print(r_word)\n",
    "            rhyming_words(r_word)\n",
    "#                     print(rhymers)\n",
    "            for rhyme in rhymers:\n",
    "                if rhyme in word_indices:\n",
    "                    z1[word_indices[rhyme]] = 10000.\n",
    "            line_count += 1\n",
    "            if quatrain_count == 3:\n",
    "                line_count += 1\n",
    "\n",
    "        elif line_count == 1:\n",
    "#                     sys.stdout.write('  SECOND LINE')\n",
    "            rhymers = []\n",
    "            z2 = np.zeros(len(words)) + 0.0001\n",
    "#                     print(\"\\nNext Word:\", next_word)\n",
    "            r_word = next_word[:].lower()\n",
    "            r_word = r_word.strip(\",.?!:;-'\\\"_\")   \n",
    "#                     print(r_word)\n",
    "            rhyming_words(r_word)\n",
    "#                     print(rhymers)\n",
    "            for rhyme in rhymers:\n",
    "                if rhyme in word_indices:\n",
    "                    z2[word_indices[rhyme]] = 10000.\n",
    "            line_count += 1\n",
    "#                     print('     LINE COUNT:', line_count, end = '')\n",
    "\n",
    "        elif line_count == 4:\n",
    "            print()\n",
    "            file.write('\\n')\n",
    "            line_count = 0\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(FILE_NAME, 'r')\n",
    "f.readline()\n",
    "f.readline()\n",
    "txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say(txt)\n",
    "engine.runAndWait()\n",
    "engine.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x + 1 for x in range(len(model_loss['loss']))], model_loss['loss'], label = 'Training Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
